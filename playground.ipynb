{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce514e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "from os import listdir\n",
    "import PIL\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9c9fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "chihuahua_dir = r\"images\\sample\\chihuahua\"\n",
    "chimgs = []\n",
    "for image_ in os.listdir(chihuahua_dir):\n",
    "    image_path = os.path.join(chihuahua_dir, image_)\n",
    "    chim = im.open(image_path, 'r')\n",
    "    small = chim.resize((32, 32))\n",
    "    chimgs.append(small)\n",
    "\n",
    "chihuahua_data = np.array(chimgs)\n",
    "print(chihuahua_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20d163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "muffin_dir = r\"images\\sample\\muffin\"\n",
    "mufimgs_pre = []\n",
    "for image_ in os.listdir(muffin_dir):\n",
    "    image_path = os.path.join(muffin_dir, image_)\n",
    "    mufim = im.open(image_path, 'r')\n",
    "    small = mufim.resize((32, 32))\n",
    "    mufimgs_pre.append(small)\n",
    "\n",
    "# one image had no color channels\n",
    "mufimgs = []\n",
    "for img in mufimgs_pre:\n",
    "    if str(np.shape(img)) == '(32, 32, 3)':\n",
    "        mufimgs.append(img)\n",
    "\n",
    "muffin_data = np.array(mufimgs)\n",
    "print(muffin_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055b720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_labels = np.zeros(chihuahua_data.shape[0]) # chihuahua -> 0\n",
    "m_labels = np.ones(muffin_data.shape[0]) # muffin -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd55de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pixels = np.concatenate((chihuahua_data, muffin_data), axis = 0)\n",
    "labels = np.concatenate((c_labels, m_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a39a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\t (1000, 32, 32, 3)\n",
      "y_train\t (1000,)\n",
      "X_val\t (91, 32, 32, 3)\n",
      "y_val\t (91,)\n",
      "X_test\t (92, 32, 32, 3)\n",
      "y_test\t (92,)\n"
     ]
    }
   ],
   "source": [
    "# currently the first 639 imgaes are of chihuahuas and the remianing are of muffins.\n",
    "# this will affect the train-val-test split. so we shuffle.\n",
    "\n",
    "indices = np.arange(image_pixels.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "shuffled_image_pixels = image_pixels[indices]\n",
    "shuffled_labels = labels[indices]\n",
    "\n",
    "X_train = shuffled_image_pixels[:1000]\n",
    "X_val = shuffled_image_pixels[1000:1091]\n",
    "X_test = shuffled_image_pixels[1091:]\n",
    "\n",
    "y_train = shuffled_labels[:1000]\n",
    "y_val = shuffled_labels[1000:1091]\n",
    "y_test = shuffled_labels[1091:]\n",
    "\n",
    "print('X_train\\t', X_train.shape)\n",
    "print('y_train\\t', y_train.shape)\n",
    "print('X_val\\t', X_val.shape)\n",
    "print('y_val\\t', y_val.shape)\n",
    "print('X_test\\t', X_test.shape)\n",
    "print('y_test\\t', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91bce4c",
   "metadata": {},
   "source": [
    "Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "458cf1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images Processed: 200\n",
      "Images Processed: 400\n",
      "Images Processed: 600\n",
      "Images Processed: 800\n",
      "Images Processed: 1000\n"
     ]
    }
   ],
   "source": [
    "# so we have X_train, which will be our image matrix of shape (1000, 32, 32, 3).\n",
    "# the filter_weights matrix will pass through the image with a specific stride. \n",
    "# a padding must be set to preserve the dimentions.\n",
    "# 1 conv layer will have 36 filters of size 7 x 7 each.\n",
    "\n",
    "filter_weights = np.random.randn(36, 7, 7, 3)\n",
    "filter_biases = np.random.randn(36,)\n",
    "\n",
    "stride = 1\n",
    "pad = 6\n",
    "image_h, image_w = X_train.shape[1], X_train.shape[2]\n",
    "filter_h, filter_w = filter_weights.shape[1], filter_weights.shape[2]\n",
    "num_images = X_train.shape[0]\n",
    "\n",
    "X_train_padded = np.pad(X_train, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode = 'constant') # input matrix\n",
    "\n",
    "# image_h_out = 1 + (image_h + 2 * pad - filter_h) // stride # formula for calculating height of output \n",
    "# image_w_out = 1 + (image_w + 2 * pad - filter_w) // stride # formula for calculating width of output\n",
    "# print(image_h_out, image_w_out)\n",
    "image_h_out = (((image_h + pad) - filter_h) // stride) + 1 # new\n",
    "image_w_out = (((image_w + pad) - filter_w) // stride) + 1 # new\n",
    "# print(image_h_out_new, image_w_out_new)\n",
    "\n",
    "channel_out = filter_weights.shape[0] # output channels\n",
    "\n",
    "out = np.zeros((num_images, image_h_out, image_w_out, channel_out))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for i in range(num_images): # for one image\n",
    "    for j in range(image_h_out): # 32\n",
    "        for k in range(image_w_out): # 32\n",
    "            for l in range(channel_out): # 36\n",
    "                h_start = j * stride # height starting index for filter traversal\n",
    "                h_end = h_start + filter_h # height ending index for filter traversal\n",
    "                w_start = k * stride # width starting index for filter traversal\n",
    "                w_end = w_start + filter_w # width ending index for filter traversal\n",
    "\n",
    "                out[i, j, k, l] = np.sum(X_train_padded[i, h_start:h_end, w_start:w_end, :] * filter_weights[l, :, :, :] * filter_biases[l]) \n",
    "\n",
    "                counter += 1\n",
    "\n",
    "    if (i + 1) % 200 == 0:\n",
    "        print('Images Processed:', i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0fa743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Pooled Output Shape for one Image: (16, 16, 36)\n"
     ]
    }
   ],
   "source": [
    "pool_h, pool_w = 2, 2 # height and width of pool region\n",
    "stride = 2\n",
    "\n",
    "num_images = out.shape[0] # 1000\n",
    "image_h = out.shape[1] # 32\n",
    "image_w = out.shape[2] # 32\n",
    "num_channels = out.shape[3] # 36\n",
    "\n",
    "# pool_h_out = 1 + (image_h - pool_h) // stride # formula for calculating height of pooled output\n",
    "# pool_w_out = 1 + (image_w - pool_w) // stride # formula for calculating width of pooled output\n",
    "# print(pool_h_out)\n",
    "\n",
    "pool_h_out = (((image_h) - pool_h) // stride) + 1 # new\n",
    "pool_w_out = (((image_w) - pool_w) // stride) + 1 # new\n",
    "# print(pool_h_out_new)\n",
    "\n",
    "pooled_out = np.zeros((num_images, pool_h_out, pool_w_out, num_channels))\n",
    "\n",
    "for i in range(num_images):\n",
    "    for j in range(pool_h_out):\n",
    "        for k in range(pool_w_out):\n",
    "            for l in range(num_channels):\n",
    "                pool_h_start = j * stride\n",
    "                pool_h_end = pool_h_start + pool_h\n",
    "                pool_w_start = k * stride\n",
    "                pool_w_end = pool_w_start + pool_w\n",
    "\n",
    "                pool_region = out[i, pool_h_start:pool_h_end, pool_w_start:pool_w_end, l] \n",
    "                pooled_out[i, j, k, l] = np.max(pool_region)\n",
    "\n",
    "print('Max Pooled Output Shape for one Image:', pooled_out.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9cf65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = pooled_out.reshape(1000, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_norm = 2 * ((flat - flat.min()) / (flat.max() - flat.min())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_sigmoid = 1 / (1 + np.exp(-flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91c734d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fully connected section has 1 hidden layer with 50 neurons\n",
    "\n",
    "input_features = flat_sigmoid.shape[1] # 9216\n",
    "neurons_layer1 = 50\n",
    "neurons_layer2 = 1\n",
    "\n",
    "w1 = np.random.randn(input_features, neurons_layer1)\n",
    "w2 = np.random.randn(neurons_layer1, neurons_layer2)\n",
    "b1 = np.random.randn(neurons_layer1)\n",
    "b2 = np.random.randn(neurons_layer2)\n",
    "\n",
    "hidden_out = np.dot(flat_sigmoid, w1) + b1 # (1000, 9216) -dot- (9216, 50) = (1000, 50)\n",
    "affine_out = np.dot(hidden_out, w2) + b2 # (1000, 50) -dot- (50, 1) = (1000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d531ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm_out = 2 * ((affine_out - affine_out.min()) / (affine_out.max() - affine_out.min())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = 1.0 / (1.0 + np.exp(-affine_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9851bc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.95469830897378\n"
     ]
    }
   ],
   "source": [
    "loss = np.sum(np.power((y_train - y_pred), 2) / 2) / len(y_train)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dc750a",
   "metadata": {},
   "source": [
    "Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebaf79c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_by_d_y_pred = y_pred - y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd588f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_y_pred_by_d_affine_out = y_pred * (1 - y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aadd12a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_affine_out_by_d_w2 = hidden_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e872027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l_w2 = d_loss_by_d_y_pred * d_y_pred_by_d_affine_out * d_affine_out_by_d_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58ad066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_affine_out_by_d_b2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8c486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l_b2 = d_loss_by_d_y_pred * d_y_pred_by_d_affine_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a48ed146",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_affine_out_by_d_hidden_out = w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022367b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden_out_by_d_w1 = flat_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l_w1 = d_loss_by_d_y_pred * d_y_pred_by_d_affine_out * d_affine_out_by_d_w2 * d_affine_out_by_d_hidden_out * d_hidden_out_by_d_w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6829cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_hidden_out_by_d_b1 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ebe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l_b1 = d_loss_by_d_y_pred * d_y_pred_by_d_affine_out * d_affine_out_by_d_hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_l_f_setup = d_loss_by_d_y_pred * d_y_pred_by_d_affine_out * d_affine_out_by_d_hidden_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
